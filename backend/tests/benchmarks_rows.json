[
  {
    "id": 152,
    "dataset_name": "AA-Omniscience-Public",
    "hf_repo": "ArtificialAnalysis/AA-Omniscience-Public",
    "author": "ArtificialAnalysis",
    "downloads": 1083,
    "tags": "[\"arxiv:2511.13029\", \"science\"]",
    "estimated_input_tokens": null,
    "repo_type": "dataset",
    "created_at_hf": "2025-11-17 06:38:58",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"AA-Omniscience_dataset_public.csv\", \"AA_Omniscience__Evaluating_Cross_Domain_Knowledge_Reliability_in_Large_Language_Models.pdf\", \"Omniscience_Index_Question_Breakdown.png\", \"README.md\"]",
    "created_at": "2026-01-20 10:13:09.430246",
    "updated_at": "2026-01-20 10:13:09.430246",
    "description": "Public Dataset for AA-Omniscience: Evaluating Cross-Domain Knowledge Reliability in Large Language Models\n\nAA-Omniscience-Public contains 600 questions across a wide range of domains used to test a model‚Äôs knowledge and hallucination tendencies.",
    "tasks": "[\"aa_omniscience\"]"
  },
  {
    "id": 145,
    "dataset_name": "arithmetic",
    "hf_repo": "EleutherAI/arithmetic",
    "author": "EleutherAI",
    "downloads": 992,
    "tags": "[\"arxiv:2005.14165\", \"math\", \"reasoning\"]",
    "estimated_input_tokens": null,
    "repo_type": "dataset",
    "created_at_hf": "2023-03-08 12:22:46",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"arithmetic.py\", \"data/five_digit_addition.jsonl\", \"data/five_digit_subtraction.jsonl\", \"data/four_digit_addition.jsonl\", \"data/four_digit_subtraction.jsonl\", \"data/single_digit_three_ops.jsonl\", \"data/three_digit_addition.jsonl\", \"data/three_digit_subtraction.jsonl\", \"data/two_digit_addition.jsonl\", \"data/two_digit_multiplication.jsonl\", \"data/two_digit_subtraction.jsonl\"]",
    "created_at": "2026-01-20 10:13:10.68094",
    "updated_at": "2026-01-20 10:13:10.68094",
    "description": "A small battery of 10 tests that involve asking language models a simple arithmetic\nproblem in natural language.",
    "tasks": "[\"arithmetic:1dc\", \"arithmetic:2da\", \"arithmetic:2dm\", \"arithmetic:2ds\", \"arithmetic:3da\", \"arithmetic:3ds\", \"arithmetic:4da\", \"arithmetic:4ds\", \"arithmetic:5da\", \"arithmetic:5ds\"]"
  },
  {
    "id": 153,
    "dataset_name": "story_cloze",
    "hf_repo": "MoE-UNC/story_cloze",
    "author": "MoE-UNC",
    "downloads": 903,
    "tags": "[]",
    "estimated_input_tokens": 85,
    "repo_type": "dataset",
    "created_at_hf": "2024-03-05 06:10:37",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/test-00000-of-00001.parquet\", \"data/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:13:17.709591",
    "updated_at": "2026-01-20 10:13:17.709591",
    "description": null,
    "tasks": "[\"storycloze:2016\", \"storycloze:2018\"]"
  },
  {
    "id": 148,
    "dataset_name": "asdiv",
    "hf_repo": "EleutherAI/asdiv",
    "author": "EleutherAI",
    "downloads": 759,
    "tags": "[]",
    "estimated_input_tokens": 9,
    "repo_type": "dataset",
    "created_at_hf": "2023-07-07 14:58:55",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"asdiv/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:13:20.94856",
    "updated_at": "2026-01-20 10:13:20.94856",
    "description": null,
    "tasks": "[\"asdiv\"]"
  },
  {
    "id": 154,
    "dataset_name": "IFBench_multi-turn",
    "hf_repo": "allenai/IFBench_multi-turn",
    "author": "allenai",
    "downloads": 696,
    "tags": "[]",
    "estimated_input_tokens": 658,
    "repo_type": "dataset",
    "created_at_hf": "2025-07-03 00:45:04",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"ifbench_constraints/test-00000-of-00001.parquet\", \"ifeval_constraints/test-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:13:25.139394",
    "updated_at": "2026-01-20 10:13:25.139394",
    "description": "This is the test data for the multi-turn setup of IFBench.\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research and educational use in accordance with Ai2's Responsible Use Guidelines. This dataset includes output data generated from third party models that are subject to separate terms governing their use.",
    "tasks": "[\"ifbench_multiturn\"]"
  },
  {
    "id": 155,
    "dataset_name": "drop_harness",
    "hf_repo": "lighteval/drop_harness",
    "author": "lighteval",
    "downloads": 622,
    "tags": "[]",
    "estimated_input_tokens": 10,
    "repo_type": "dataset",
    "created_at_hf": "2023-07-27 11:58:48",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/train-00000-of-00001-89d8e1e5f2988090.parquet\", \"data/validation-00000-of-00001-1b0a18bf14d15be8.parquet\"]",
    "created_at": "2026-01-20 10:13:28.885011",
    "updated_at": "2026-01-20 10:13:28.885011",
    "description": "More Information needed",
    "tasks": "[\"drop\"]"
  },
  {
    "id": 156,
    "dataset_name": "lexglue",
    "hf_repo": "lighteval/lexglue",
    "author": "lighteval",
    "downloads": 528,
    "tags": "[]",
    "estimated_input_tokens": 1812,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-10 14:11:47",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"all/test-00000-of-00001.parquet\", \"all/train-00000-of-00002.parquet\", \"all/train-00001-of-00002.parquet\", \"all/validation-00000-of-00001.parquet\", \"case_hold/test-00000-of-00001.parquet\", \"case_hold/train-00000-of-00001.parquet\", \"case_hold/validation-00000-of-00001.parquet\", \"ecthr_a/test-00000-of-00001.parquet\", \"ecthr_a/train-00000-of-00001.parquet\", \"ecthr_a/validation-00000-of-00001.parquet\", \"ecthr_b/test-00000-of-00001.parquet\", \"ecthr_b/train-00000-of-00001.parquet\", \"ecthr_b/validation-00000-of-00001.parquet\", \"eurlex/test-00000-of-00001.parquet\", \"eurlex/train-00000-of-00001.parquet\", \"eurlex/validation-00000-of-00001.parquet\", \"ledgar/test-00000-of-00001.parquet\", \"ledgar/train-00000-of-00001.parquet\", \"ledgar/validation-00000-of-00001.parquet\", \"scotus/test-00000-of-00001.parquet\", \"scotus/train-00000-of-00001.parquet\", \"scotus/validation-00000-of-00001.parquet\", \"unfair_tos/test-00000-of-00001.parquet\", \"unfair_tos/train-00000-of-00001.parquet\", \"unfair_tos/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:13:34.287397",
    "updated_at": "2026-01-20 10:13:34.287397",
    "description": null,
    "tasks": "[\"lexglue:case_hold\", \"lexglue:ecthr_a\", \"lexglue:ecthr_b\", \"lexglue:eurlex\", \"lexglue:ledgar\", \"lexglue:scotus\", \"lexglue:unfair_tos\"]"
  },
  {
    "id": 150,
    "dataset_name": "wikifact",
    "hf_repo": "lighteval/wikifact",
    "author": "lighteval",
    "downloads": 520,
    "tags": "[]",
    "estimated_input_tokens": 11,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-12 12:34:58",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"applies_to_jurisdiction/test-00000-of-00001.parquet\", \"author/test-00000-of-00001.parquet\", \"award_received/test-00000-of-00001.parquet\", \"basic_form_of_government/test-00000-of-00001.parquet\", \"capital/test-00000-of-00001.parquet\", \"capital_of/test-00000-of-00001.parquet\", \"central_bank/test-00000-of-00001.parquet\", \"composer/test-00000-of-00001.parquet\", \"continent/test-00000-of-00001.parquet\", \"country/test-00000-of-00001.parquet\", \"country_of_citizenship/test-00000-of-00001.parquet\", \"country_of_origin/test-00000-of-00001.parquet\", \"creator/test-00000-of-00001.parquet\", \"currency/test-00000-of-00001.parquet\", \"defendant/test-00000-of-00001.parquet\", \"developer/test-00000-of-00001.parquet\", \"diplomatic_relation/test-00000-of-00001.parquet\", \"director/test-00000-of-00001.parquet\", \"discoverer_or_inventor/test-00000-of-00001.parquet\", \"drug_or_therapy_used_for_treatment/test-00000-of-00001.parquet\", \"educated_at/test-00000-of-00001.parquet\", \"employer/test-00000-of-00001.parquet\", \"field_of_work/test-00000-of-00001.parquet\", \"genetic_association/test-00000-of-00001.parquet\", \"genre/test-00000-of-00001.parquet\", \"has_part/test-00000-of-00001.parquet\", \"head_of_government/test-00000-of-00001.parquet\", \"head_of_state/test-00000-of-00001.parquet\", \"headquarters_location/test-00000-of-00001.parquet\", \"industry/test-00000-of-00001.parquet\", \"influenced_by/test-00000-of-00001.parquet\", \"instance_of/test-00000-of-00001.parquet\", \"instrument/test-00000-of-00001.parquet\", \"language_of_work_or_name/test-00000-of-00001.parquet\", \"languages_spoken_written_or_signed/test-00000-of-00001.parquet\", \"laws_applied/test-00000-of-00001.parquet\", \"located_in_the_administrative_territorial_entity/test-00000-of-00001.parquet\", \"location/test-00000-of-00001.parquet\", \"location_of_discovery/test-00000-of-00001.parquet\", \"location_of_formation/test-00000-of-00001.parquet\", \"majority_opinion_by/test-00000-of-00001.parquet\", \"manufacturer/test-00000-of-00001.parquet\", \"measured_physical_quantity/test-00000-of-00001.parquet\", \"medical_condition_treated/test-00000-of-00001.parquet\", \"member_of/test-00000-of-00001.parquet\", \"member_of_political_party/test-00000-of-00001.parquet\", \"member_of_sports_team/test-00000-of-00001.parquet\", \"movement/test-00000-of-00001.parquet\", \"named_after/test-00000-of-00001.parquet\", \"native_language/test-00000-of-00001.parquet\", \"occupation/test-00000-of-00001.parquet\", \"office_held_by_head_of_government/test-00000-of-00001.parquet\", \"office_held_by_head_of_state/test-00000-of-00001.parquet\", \"official_language/test-00000-of-00001.parquet\", \"operating_system/test-00000-of-00001.parquet\", \"original_language_of_film_or_TV_show/test-00000-of-00001.parquet\", \"original_network/test-00000-of-00001.parquet\", \"overrules/test-00000-of-00001.parquet\", \"owned_by/test-00000-of-00001.parquet\", \"part_of/test-00000-of-00001.parquet\", \"participating_team/test-00000-of-00001.parquet\", \"place_of_birth/test-00000-of-00001.parquet\", \"place_of_death/test-00000-of-00001.parquet\", \"plaintiff/test-00000-of-00001.parquet\", \"position_held/test-00000-of-00001.parquet\", \"position_played_on_team/test-00000-of-00001.parquet\", \"programming_language/test-00000-of-00001.parquet\", \"recommended_unit_of_measurement/test-00000-of-00001.parquet\", \"record_label/test-00000-of-00001.parquet\", \"religion/test-00000-of-00001.parquet\", \"repealed_by/test-00000-of-00001.parquet\", \"shares_border_with/test-00000-of-00001.parquet\", \"solved_by/test-00000-of-00001.parquet\", \"statement_describes/test-00000-of-00001.parquet\", \"stock_exchange/test-00000-of-00001.parquet\", \"subclass_of/test-00000-of-00001.parquet\", \"subsidiary/test-00000-of-00001.parquet\", \"symptoms_and_signs/test-00000-of-00001.parquet\", \"therapeutic_area/test-00000-of-00001.parquet\", \"twinned_administrative_body/test-00000-of-00001.parquet\", \"work_location/test-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:13:38.481089",
    "updated_at": "2026-01-20 10:13:38.481089",
    "description": null,
    "tasks": "[\"wikifact:applies_to_jurisdiction\", \"wikifact:atomic_number\", \"wikifact:author\", \"wikifact:employer\", \"wikifact:field_of_work\", \"wikifact:file_extension\", \"wikifact:genetic_association\", \"wikifact:headquarters_location\", \"wikifact:industry\", \"wikifact:instrument\", \"wikifact:language_of_work_or_name\", \"wikifact:languages_spoken_written_or_signed\", \"wikifact:laws_applied\", \"wikifact:located_in_the_administrative_territorial_entity\", \"wikifact:location\", \"wikifact:location_of_discovery\", \"wikifact:location_of_formation\", \"wikifact:member_of\", \"wikifact:member_of_political_party\", \"wikifact:member_of_sports_team\", \"wikifact:movement\", \"wikifact:named_after\", \"wikifact:native_language\", \"wikifact:number_of_processor_cores\", \"wikifact:occupation\", \"wikifact:original_language_of_film_or_TV_show\", \"wikifact:original_network\", \"wikifact:overrules\", \"wikifact:owned_by\", \"wikifact:part_of\", \"wikifact:participating_team\", \"wikifact:place_of_birth\", \"wikifact:place_of_death\", \"wikifact:position_played_on_team\", \"wikifact:programming_language\", \"wikifact:recommended_unit_of_measurement\", \"wikifact:record_label\", \"wikifact:religion\", \"wikifact:repealed_by\", \"wikifact:shares_border_with\", \"wikifact:solved_by\", \"wikifact:statement_describes\", \"wikifact:stock_exchange\", \"wikifact:subclass_of\", \"wikifact:subsidiary\", \"wikifact:symptoms_and_signs\", \"wikifact:therapeutic_area\", \"wikifact:time_of_discovery_or_invention\", \"wikifact:twinned_administrative_body\", \"wikifact:work_location\"]"
  },
  {
    "id": 157,
    "dataset_name": "lextreme",
    "hf_repo": "lighteval/lextreme",
    "author": "lighteval",
    "downloads": 424,
    "tags": "[]",
    "estimated_input_tokens": 416,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-10 13:52:11",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"all/test-00000-of-00002.parquet\", \"all/test-00001-of-00002.parquet\", \"brazilian_court_decisions_judgment/test-00000-of-00001.parquet\", \"brazilian_court_decisions_unanimity/test-00000-of-00001.parquet\", \"covid19_emergency_event/test-00000-of-00001.parquet\", \"german_argument_mining/test-00000-of-00001.parquet\", \"greek_legal_code_chapter/test-00000-of-00001.parquet\", \"greek_legal_code_subject/test-00000-of-00001.parquet\", \"greek_legal_code_volume/test-00000-of-00001.parquet\", \"greek_legal_ner/test-00000-of-00001.parquet\", \"legalnero/test-00000-of-00001.parquet\", \"lener_br/test-00000-of-00001.parquet\", \"mapa_coarse/test-00000-of-00001.parquet\", \"mapa_fine/test-00000-of-00001.parquet\", \"multi_eurlex_level_1/test-00000-of-00001.parquet\", \"multi_eurlex_level_2/test-00000-of-00001.parquet\", \"multi_eurlex_level_3/test-00000-of-00001.parquet\", \"online_terms_of_service_clause_topics/test-00000-of-00001.parquet\", \"online_terms_of_service_unfairness_levels/test-00000-of-00001.parquet\", \"swiss_judgment_prediction/test-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:13:45.149684",
    "updated_at": "2026-01-20 10:13:45.149684",
    "description": null,
    "tasks": "[\"lextreme:brazilian_court_decisions_judgment\", \"lextreme:brazilian_court_decisions_unanimity\", \"lextreme:covid19_emergency_event\", \"lextreme:german_argument_mining\", \"lextreme:greek_legal_code_chapter\", \"lextreme:greek_legal_code_subject\", \"lextreme:greek_legal_code_volume\", \"lextreme:greek_legal_ner\", \"lextreme:legalnero\", \"lextreme:lener_br\", \"lextreme:mapa_coarse\", \"lextreme:mapa_fine\", \"lextreme:multi_eurlex_level_1\", \"lextreme:multi_eurlex_level_2\", \"lextreme:multi_eurlex_level_3\", \"lextreme:online_terms_of_service_clause_topics\", \"lextreme:online_terms_of_service_unfairness_levels\", \"lextreme:swiss_judgment_prediction\"]"
  },
  {
    "id": 151,
    "dataset_name": "SimpleQA",
    "hf_repo": "lighteval/SimpleQA",
    "author": "OpenEvals",
    "downloads": 407,
    "tags": "[\"qa\"]",
    "estimated_input_tokens": 27,
    "repo_type": "dataset",
    "created_at_hf": "2025-01-28 13:55:50",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/few_shot-00000-of-00001.parquet\", \"data/test-00000-of-00001.parquet\", \"eval.yaml\"]",
    "created_at": "2026-01-20 10:13:50.766438",
    "updated_at": "2026-01-20 10:13:50.766438",
    "description": "SimpleQA is a factuality benchmark developed by OpenAI to evaluate the factual accuracy of language models when answering concise, fact-seeking questions. The dataset comprises 4,326 questions spanning diverse topics including science, technology, entertainment, and more.\n\nSimpleQA measures the ability for language models to answer short, fact-seeking questions.",
    "tasks": "[\"simpleqa\"]"
  },
  {
    "id": 158,
    "dataset_name": "babi_qa",
    "hf_repo": "facebook/babi_qa",
    "author": "facebook",
    "downloads": 309,
    "tags": "[\"language:en\", \"arxiv:1502.05698\", \"arxiv:1511.06931\", \"qa\"]",
    "estimated_input_tokens": null,
    "repo_type": "dataset",
    "created_at_hf": "2022-03-02 23:29:22",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"babi_qa.py\", \"dataset_infos.json\"]",
    "created_at": "2026-01-20 10:13:51.847513",
    "updated_at": "2026-01-20 10:13:51.847513",
    "description": "The (20) QA bAbI tasks are a set of proxy tasks that evaluate reading\ncomprehension via question answering. Our tasks measure understanding\nin several ways: whether a system is able to answer questions via chaining facts,\nsimple induction, deduction and many more. The tasks are designed to be prerequisites\nfor any system that aims to be capable of conversing with a human.",
    "tasks": "[\"babi_qa\"]"
  },
  {
    "id": 159,
    "dataset_name": "SLR-Bench",
    "hf_repo": "AIML-TUDA/SLR-Bench",
    "author": "AIML-TUDA",
    "downloads": 301,
    "tags": "[\"language:en\", \"arxiv:2506.15787\", \"reasoning\"]",
    "estimated_input_tokens": 574,
    "repo_type": "dataset",
    "created_at_hf": "2025-06-19 05:56:24",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"v1-All/test-00000-of-00001.parquet\", \"v1-All/train-00000-of-00002.parquet\", \"v1-All/train-00001-of-00002.parquet\", \"v1-All/validation-00000-of-00001.parquet\", \"v1-Basic/test-00000-of-00001.parquet\", \"v1-Basic/train-00000-of-00001.parquet\", \"v1-Basic/validation-00000-of-00001.parquet\", \"v1-Easy/test-00000-of-00001.parquet\", \"v1-Easy/train-00000-of-00001.parquet\", \"v1-Easy/validation-00000-of-00001.parquet\", \"v1-Hard/test-00000-of-00001.parquet\", \"v1-Hard/train-00000-of-00002.parquet\", \"v1-Hard/train-00001-of-00002.parquet\", \"v1-Hard/validation-00000-of-00001.parquet\", \"v1-Medium/test-00000-of-00001.parquet\", \"v1-Medium/train-00000-of-00001.parquet\", \"v1-Medium/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:13:56.544807",
    "updated_at": "2026-01-20 10:13:56.544807",
    "description": "üÜï August 2025: Build your own Reasoning Problems with Verifiable Rewards. Source Code is now available! üëâ Generate your own Reasoning Task\n\nüÜï June 2024: Evaluation & RLVR Reward Model Released! üëâ Demo on Hugging Face Spaces",
    "tasks": "[\"slr_bench_all\", \"slr_bench_basic\", \"slr_bench_easy\", \"slr_bench_hard\", \"slr_bench_medium\"]"
  },
  {
    "id": 160,
    "dataset_name": "boolq_helm",
    "hf_repo": "lighteval/boolq_helm",
    "author": "lighteval",
    "downloads": 272,
    "tags": "[]",
    "estimated_input_tokens": 11,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-04 09:56:35",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/train-00000-of-00001.parquet\", \"data/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:13:59.873769",
    "updated_at": "2026-01-20 10:13:59.873769",
    "description": null,
    "tasks": "[\"boolq\", \"boolq:contrastset\"]"
  },
  {
    "id": 149,
    "dataset_name": "small_natural_questions",
    "hf_repo": "lighteval/small_natural_questions",
    "author": "lighteval",
    "downloads": 223,
    "tags": "[\"qa\"]",
    "estimated_input_tokens": 10,
    "repo_type": "dataset",
    "created_at_hf": "2025-01-29 10:43:10",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/few_shot-00000-of-00001.parquet\", \"data/test-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:14:01.805946",
    "updated_at": "2026-01-20 10:14:01.805946",
    "description": null,
    "tasks": "[\"natural_questions\"]"
  },
  {
    "id": 161,
    "dataset_name": "bbq_helm",
    "hf_repo": "lighteval/bbq_helm",
    "author": "lighteval",
    "downloads": 192,
    "tags": "[]",
    "estimated_input_tokens": 6,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-03 08:01:49",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"Age/test-00000-of-00001.parquet\", \"Disability_status/test-00000-of-00001.parquet\", \"Gender_identity/test-00000-of-00001.parquet\", \"Nationality/test-00000-of-00001.parquet\", \"Physical_appearance/test-00000-of-00001.parquet\", \"README.md\", \"Race_ethnicity/test-00000-of-00001.parquet\", \"Race_x_SES/test-00000-of-00001.parquet\", \"Race_x_gender/test-00000-of-00001.parquet\", \"Religion/test-00000-of-00001.parquet\", \"SES/test-00000-of-00001.parquet\", \"Sexual_orientation/test-00000-of-00001.parquet\", \"all/test-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:14:08.650805",
    "updated_at": "2026-01-20 10:14:08.650805",
    "description": null,
    "tasks": "[\"bbq\", \"bbq:Age\", \"bbq:Disability_status\", \"bbq:Gender_identity\", \"bbq:Nationality\", \"bbq:Physical_appearance\", \"bbq:Race_ethnicity\", \"bbq:Race_x_SES\", \"bbq:Race_x_gender\", \"bbq:Religion\", \"bbq:SES\", \"bbq:Sexual_orientation\"]"
  },
  {
    "id": 162,
    "dataset_name": "med_dialog",
    "hf_repo": "lighteval/med_dialog",
    "author": "lighteval",
    "downloads": 155,
    "tags": "[\"dialogue\"]",
    "estimated_input_tokens": 229,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-11 07:01:32",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"healthcaremagic/test-00000-of-00001.parquet\", \"healthcaremagic/train-00000-of-00001.parquet\", \"healthcaremagic/validation-00000-of-00001.parquet\", \"icliniq/test-00000-of-00001.parquet\", \"icliniq/train-00000-of-00001.parquet\", \"icliniq/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:14:12.70027",
    "updated_at": "2026-01-20 10:14:12.70027",
    "description": null,
    "tasks": "[\"med_dialog:healthcaremagic\", \"med_dialog:icliniq\"]"
  },
  {
    "id": 163,
    "dataset_name": "med_mcqa",
    "hf_repo": "lighteval/med_mcqa",
    "author": "lighteval",
    "downloads": 154,
    "tags": "[\"arxiv:2203.14371\", \"qa\"]",
    "estimated_input_tokens": 12,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-11 07:18:58",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"dev.json\", \"test.json\", \"train.json\"]",
    "created_at": "2026-01-20 10:14:14.885396",
    "updated_at": "2026-01-20 10:14:14.885396",
    "description": "From \"MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering\"\n(Pal et al.), MedMCQA is a \"multiple-choice question answering (MCQA) dataset designed to address\nreal-world medical entrance exam questions.\" The dataset \"...has more than 194k high-quality AIIMS & NEET PG\nentrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average\ntoken length of 12.77 and high topical diversity.",
    "tasks": "[\"med_mcqa\"]"
  },
  {
    "id": 164,
    "dataset_name": "MixEval",
    "hf_repo": "MixEval/MixEval",
    "author": "MixEval",
    "downloads": 148,
    "tags": "[\"language:en\", \"arxiv:2406.06565\", \"language\", \"multimodal\"]",
    "estimated_input_tokens": null,
    "repo_type": "dataset",
    "created_at_hf": "2024-06-01 04:38:38",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \".gitignore\", \"README.md\", \"data/mixeval-jsonl/mixeval-hard/free-form.jsonl\", \"data/mixeval-jsonl/mixeval-hard/multiple-choice.jsonl\", \"data/mixeval-jsonl/mixeval/free-form.jsonl\", \"data/mixeval-jsonl/mixeval/multiple-choice.jsonl\", \"resources/imgs/arena_cost.jpg\", \"resources/imgs/corr_breakdown_arena_elo.png\", \"resources/imgs/corr_breakdown_arena_elo_en.png\", \"resources/imgs/header.png\", \"resources/imgs/linear_with_arena_merged.png\", \"resources/imgs/mixeval_keystats.png\", \"resources/imgs/mixeval_pipeline.png\"]",
    "created_at": "2026-01-20 10:14:19.505742",
    "updated_at": "2026-01-20 10:14:19.505742",
    "description": "üè† Homepage | üë®‚Äçüíª Github | üèÜ Leaderboard | üìú arXiv | üìù blog | ü§ó HF Paper | ùïè Twitter\n\nBenchmark correlations (%) with Chatbot Arena Elo, against the total costs of evaluating a single GPT-3.5-Turbo-0125 model. MixEval and MixEval-Hard show the highest correlations with Arena Elo and Arena Elo (En) among leading benchmarks. We reference the crowdsourcing price for Amazon Mechanical Turk ($0.",
    "tasks": "[\"mixeval_easy:freeform\", \"mixeval_easy:multichoice\", \"mixeval_hard:freeform\", \"mixeval_hard:multichoice\"]"
  },
  {
    "id": 165,
    "dataset_name": "summarization",
    "hf_repo": "lighteval/summarization",
    "author": "lighteval",
    "downloads": 110,
    "tags": "[\"summarization\"]",
    "estimated_input_tokens": 609,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-12 08:33:56",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"cnn-dm/test-00000-of-00001.parquet\", \"cnn-dm/train-00000-of-00001.parquet\", \"cnn-dm/validation-00000-of-00001.parquet\", \"xsum-sampled/test-00000-of-00001.parquet\", \"xsum-sampled/train-00000-of-00001.parquet\", \"xsum-sampled/validation-00000-of-00001.parquet\", \"xsum/test-00000-of-00001.parquet\", \"xsum/train-00000-of-00001.parquet\", \"xsum/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:14:26.547115",
    "updated_at": "2026-01-20 10:14:26.547115",
    "description": null,
    "tasks": "[\"summarization:cnn-dm\", \"summarization:xsum\", \"summarization:xsum-sampled\"]"
  },
  {
    "id": 166,
    "dataset_name": "lsat_qa",
    "hf_repo": "lighteval/lsat_qa",
    "author": "lighteval",
    "downloads": 108,
    "tags": "[\"qa\"]",
    "estimated_input_tokens": 21,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-10 15:33:08",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"all/test-00000-of-00001.parquet\", \"assignment/test-00000-of-00001.parquet\", \"grouping/test-00000-of-00001.parquet\", \"miscellaneous/test-00000-of-00001.parquet\", \"ordering/test-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:14:33.150684",
    "updated_at": "2026-01-20 10:14:33.150684",
    "description": null,
    "tasks": "[\"lsat_qa\", \"lsat_qa:assignment\", \"lsat_qa:grouping\", \"lsat_qa:miscellaneous\", \"lsat_qa:ordering\"]"
  },
  {
    "id": 167,
    "dataset_name": "numeracy",
    "hf_repo": "lighteval/numeracy",
    "author": "lighteval",
    "downloads": 93,
    "tags": "[]",
    "estimated_input_tokens": 6,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-12 12:17:50",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"linear_example/test-00000-of-00001.parquet\", \"linear_example/train-00000-of-00001.parquet\", \"linear_standard/test-00000-of-00001.parquet\", \"linear_standard/train-00000-of-00001.parquet\", \"parabola_example/test-00000-of-00001.parquet\", \"parabola_example/train-00000-of-00001.parquet\", \"parabola_standard/test-00000-of-00001.parquet\", \"parabola_standard/train-00000-of-00001.parquet\", \"paraboloid_example/test-00000-of-00001.parquet\", \"paraboloid_example/train-00000-of-00001.parquet\", \"paraboloid_standard/test-00000-of-00001.parquet\", \"paraboloid_standard/train-00000-of-00001.parquet\", \"plane_example/test-00000-of-00001.parquet\", \"plane_example/train-00000-of-00001.parquet\", \"plane_standard/test-00000-of-00001.parquet\", \"plane_standard/train-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:14:39.178742",
    "updated_at": "2026-01-20 10:14:39.178742",
    "description": null,
    "tasks": "[\"numeracy:linear_example\", \"numeracy:linear_standard\", \"numeracy:parabola_example\", \"numeracy:parabola_standard\", \"numeracy:paraboloid_example\", \"numeracy:paraboloid_standard\", \"numeracy:plane_example\", \"numeracy:plane_standard\"]"
  },
  {
    "id": 168,
    "dataset_name": "DyckLanguage",
    "hf_repo": "lighteval/DyckLanguage",
    "author": "lighteval",
    "downloads": 80,
    "tags": "[]",
    "estimated_input_tokens": 71,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-12 12:04:30",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"2/test-00000-of-00001.parquet\", \"2/train-00000-of-00001.parquet\", \"3/test-00000-of-00001.parquet\", \"3/train-00000-of-00001.parquet\", \"4/test-00000-of-00001.parquet\", \"4/train-00000-of-00001.parquet\", \"README.md\"]",
    "created_at": "2026-01-20 10:14:45.230179",
    "updated_at": "2026-01-20 10:14:45.230179",
    "description": null,
    "tasks": "[\"dyck_language:2\", \"dyck_language:3\", \"dyck_language:4\"]"
  },
  {
    "id": 169,
    "dataset_name": "legal_summarization",
    "hf_repo": "lighteval/legal_summarization",
    "author": "lighteval",
    "downloads": 78,
    "tags": "[\"summarization\", \"legal\"]",
    "estimated_input_tokens": 1925,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-12 14:01:58",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"BillSum/test-00000-of-00001.parquet\", \"BillSum/train-00000-of-00001.parquet\", \"EurLexSum/test-00000-of-00001.parquet\", \"EurLexSum/train-00000-of-00001.parquet\", \"EurLexSum/validation-00000-of-00001.parquet\", \"MultiLexSum/test-00000-of-00001.parquet\", \"MultiLexSum/train-00000-of-00001.parquet\", \"MultiLexSum/validation-00000-of-00001.parquet\", \"README.md\"]",
    "created_at": "2026-01-20 10:14:51.769796",
    "updated_at": "2026-01-20 10:14:51.769796",
    "description": null,
    "tasks": "[\"legal_summarization:billsum\", \"legal_summarization:eurlexsum\", \"legal_summarization:multilexsum\"]"
  },
  {
    "id": 170,
    "dataset_name": "arc-agi-2",
    "hf_repo": "arc-agi-community/arc-agi-2",
    "author": "arc-agi-community",
    "downloads": 67,
    "tags": "[\"arxiv:1911.01547\"]",
    "estimated_input_tokens": 2705,
    "repo_type": "dataset",
    "created_at_hf": "2025-03-25 15:06:15",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/test-00000-of-00001.parquet\", \"data/train-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:14:55.924045",
    "updated_at": "2026-01-20 10:14:55.924045",
    "description": "Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI-2)\n\nThis repository contains the ARC-AGI-2 task data from here.\n\"ARC can be seen as a general artificial intelligence benchmark, as a program synthesis benchmark, or as a psychometric intelligence test. It is targeted at both humans and artificially intelligent systems that aim at emulating a human-like form of general fluid intelligence.",
    "tasks": "[\"arc_agi_2\"]"
  },
  {
    "id": 171,
    "dataset_name": "EntityMatching",
    "hf_repo": "lighteval/EntityMatching",
    "author": "lighteval",
    "downloads": 57,
    "tags": "[]",
    "estimated_input_tokens": 128,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-09 14:56:27",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"Abt_Buy/test-00000-of-00001.parquet\", \"Abt_Buy/train-00000-of-00001.parquet\", \"Abt_Buy/validation-00000-of-00001.parquet\", \"Amazon_Google/test-00000-of-00001.parquet\", \"Amazon_Google/train-00000-of-00001.parquet\", \"Amazon_Google/validation-00000-of-00001.parquet\", \"Beer/test-00000-of-00001.parquet\", \"Beer/train-00000-of-00001.parquet\", \"Beer/validation-00000-of-00001.parquet\", \"Company/test-00000-of-00001.parquet\", \"Company/train-00000-of-00001.parquet\", \"Company/validation-00000-of-00001.parquet\", \"DBLP_ACM/test-00000-of-00001.parquet\", \"DBLP_ACM/train-00000-of-00001.parquet\", \"DBLP_ACM/validation-00000-of-00001.parquet\", \"DBLP_GoogleScholar/test-00000-of-00001.parquet\", \"DBLP_GoogleScholar/train-00000-of-00001.parquet\", \"DBLP_GoogleScholar/validation-00000-of-00001.parquet\", \"Dirty_DBLP_ACM/test-00000-of-00001.parquet\", \"Dirty_DBLP_ACM/train-00000-of-00001.parquet\", \"Dirty_DBLP_ACM/validation-00000-of-00001.parquet\", \"Dirty_DBLP_GoogleScholar/test-00000-of-00001.parquet\", \"Dirty_DBLP_GoogleScholar/train-00000-of-00001.parquet\", \"Dirty_DBLP_GoogleScholar/validation-00000-of-00001.parquet\", \"Dirty_Walmart_Amazon/test-00000-of-00001.parquet\", \"Dirty_Walmart_Amazon/train-00000-of-00001.parquet\", \"Dirty_Walmart_Amazon/validation-00000-of-00001.parquet\", \"Dirty_iTunes_Amazon/test-00000-of-00001.parquet\", \"Dirty_iTunes_Amazon/train-00000-of-00001.parquet\", \"Dirty_iTunes_Amazon/validation-00000-of-00001.parquet\", \"Fodors_Zagats/test-00000-of-00001.parquet\", \"Fodors_Zagats/train-00000-of-00001.parquet\", \"Fodors_Zagats/validation-00000-of-00001.parquet\", \"README.md\", \"Walmart_Amazon/test-00000-of-00001.parquet\", \"Walmart_Amazon/train-00000-of-00001.parquet\", \"Walmart_Amazon/validation-00000-of-00001.parquet\", \"iTunes_Amazon/test-00000-of-00001.parquet\", \"iTunes_Amazon/train-00000-of-00001.parquet\", \"iTunes_Amazon/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:14:59.836382",
    "updated_at": "2026-01-20 10:14:59.836382",
    "description": null,
    "tasks": "[\"entity_matching:Abt_Buy\", \"entity_matching:Amazon_Google\", \"entity_matching:Beer\", \"entity_matching:Company\", \"entity_matching:DBLP_ACM\", \"entity_matching:DBLP_GoogleScholar\", \"entity_matching:Dirty_DBLP_ACM\", \"entity_matching:Dirty_DBLP_GoogleScholar\", \"entity_matching:Dirty_Walmart_Amazon\", \"entity_matching:Dirty_iTunes_Amazon\", \"entity_matching:Walmart_Amazon\", \"entity_matching:iTunes_Amazon\", \"entity_matching=Fodors_Zagats\"]"
  },
  {
    "id": 172,
    "dataset_name": "med_paragraph_simplification",
    "hf_repo": "lighteval/med_paragraph_simplification",
    "author": "lighteval",
    "downloads": 56,
    "tags": "[]",
    "estimated_input_tokens": 466,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-11 07:49:32",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/test-00000-of-00001.parquet\", \"data/train-00000-of-00001.parquet\", \"data/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:15:02.676702",
    "updated_at": "2026-01-20 10:15:02.676702",
    "description": null,
    "tasks": "[\"med_paragraph_simplification\"]"
  },
  {
    "id": 173,
    "dataset_name": "mt-bench",
    "hf_repo": "lighteval/mt-bench",
    "author": "lighteval",
    "downloads": 55,
    "tags": "[]",
    "estimated_input_tokens": null,
    "repo_type": "dataset",
    "created_at_hf": "2024-03-19 20:52:13",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/train-00000-of-00001-e9f46de18aadac31.parquet\"]",
    "created_at": "2026-01-20 10:15:05.881448",
    "updated_at": "2026-01-20 10:15:05.881448",
    "description": "More Information needed",
    "tasks": "[\"mt_bench\"]"
  },
  {
    "id": 174,
    "dataset_name": "civil_comments_helm",
    "hf_repo": "lighteval/civil_comments_helm",
    "author": "lighteval",
    "downloads": 39,
    "tags": "[]",
    "estimated_input_tokens": 62,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-04 12:02:46",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"LGBTQ/test-00000-of-00001.parquet\", \"LGBTQ/train-00000-of-00001.parquet\", \"README.md\", \"all/test-00000-of-00001.parquet\", \"all/train-00000-of-00001.parquet\", \"black/test-00000-of-00001.parquet\", \"black/train-00000-of-00001.parquet\", \"christian/test-00000-of-00001.parquet\", \"christian/train-00000-of-00001.parquet\", \"female/test-00000-of-00001.parquet\", \"female/train-00000-of-00001.parquet\", \"male/test-00000-of-00001.parquet\", \"male/train-00000-of-00001.parquet\", \"muslim/test-00000-of-00001.parquet\", \"muslim/train-00000-of-00001.parquet\", \"other_religions/test-00000-of-00001.parquet\", \"other_religions/train-00000-of-00001.parquet\", \"white/test-00000-of-00001.parquet\", \"white/train-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:15:10.135469",
    "updated_at": "2026-01-20 10:15:10.135469",
    "description": null,
    "tasks": "[\"civil_comments:LGBTQ\", \"civil_comments:black\", \"civil_comments:christian\", \"civil_comments:female\", \"civil_comments:male\", \"civil_comments:muslim\", \"civil_comments:other_religions\", \"civil_comments:white\"]"
  },
  {
    "id": 175,
    "dataset_name": "synthetic_reasoning",
    "hf_repo": "lighteval/synthetic_reasoning",
    "author": "lighteval",
    "downloads": 38,
    "tags": "[\"reasoning\"]",
    "estimated_input_tokens": 27,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-12 09:46:29",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"induction/test-00000-of-00001.parquet\", \"induction/train-00000-of-00001.parquet\", \"induction/validation-00000-of-00001.parquet\", \"pattern_match/test-00000-of-00001.parquet\", \"pattern_match/train-00000-of-00001.parquet\", \"pattern_match/validation-00000-of-00001.parquet\", \"variable_substitution/test-00000-of-00001.parquet\", \"variable_substitution/train-00000-of-00001.parquet\", \"variable_substitution/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:15:13.750759",
    "updated_at": "2026-01-20 10:15:13.750759",
    "description": null,
    "tasks": "[\"synthetic_reasoning:induction\", \"synthetic_reasoning:pattern_match\", \"synthetic_reasoning:variable_substitution\"]"
  },
  {
    "id": 176,
    "dataset_name": "jeopardy",
    "hf_repo": "openaccess-ai-collective/jeopardy",
    "author": "openaccess-ai-collective",
    "downloads": 35,
    "tags": "[]",
    "estimated_input_tokens": null,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-07 23:47:52",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/train.jsonl\"]",
    "created_at": "2026-01-20 10:15:16.47957",
    "updated_at": "2026-01-20 10:15:16.47957",
    "description": null,
    "tasks": "[\"jeopardy\"]"
  },
  {
    "id": 177,
    "dataset_name": "covid_dialogue",
    "hf_repo": "lighteval/covid_dialogue",
    "author": "lighteval",
    "downloads": 34,
    "tags": "[\"dialogue\"]",
    "estimated_input_tokens": 54,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-05 13:37:08",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/test-00000-of-00001.parquet\", \"data/train-00000-of-00001.parquet\", \"data/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:15:21.292514",
    "updated_at": "2026-01-20 10:15:21.292514",
    "description": null,
    "tasks": "[\"covid_dialogue\"]"
  },
  {
    "id": 178,
    "dataset_name": "synthetic_reasoning_natural",
    "hf_repo": "lighteval/synthetic_reasoning_natural",
    "author": "lighteval",
    "downloads": 33,
    "tags": "[\"reasoning\"]",
    "estimated_input_tokens": 89,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-12 08:59:11",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"easy/test-00000-of-00001.parquet\", \"easy/train-00000-of-00001.parquet\", \"easy/validation-00000-of-00001.parquet\", \"hard/test-00000-of-00001.parquet\", \"hard/train-00000-of-00001.parquet\", \"hard/validation-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:15:28.245841",
    "updated_at": "2026-01-20 10:15:28.245841",
    "description": null,
    "tasks": "[\"synthetic_reasoning:natural_easy\", \"synthetic_reasoning:natural_hard\"]"
  },
  {
    "id": 179,
    "dataset_name": "narrative_qa_helm",
    "hf_repo": "lighteval/narrative_qa_helm",
    "author": "lighteval",
    "downloads": 13,
    "tags": "[\"qa\"]",
    "estimated_input_tokens": 10,
    "repo_type": "dataset",
    "created_at_hf": "2023-06-14 12:29:40",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"test.jsonl\", \"train.jsonl\", \"valid.jsonl\"]",
    "created_at": "2026-01-20 10:15:31.147244",
    "updated_at": "2026-01-20 10:15:31.147244",
    "description": null,
    "tasks": "[\"narrativeqa\"]"
  },
  {
    "id": 180,
    "dataset_name": "aimo_progress_prize_1",
    "hf_repo": "lighteval/aimo_progress_prize_1",
    "author": "lighteval",
    "downloads": 8,
    "tags": "[]",
    "estimated_input_tokens": null,
    "repo_type": "dataset",
    "created_at_hf": "2024-04-10 19:13:30",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/train-00000-of-00001.parquet\"]",
    "created_at": "2026-01-20 10:15:34.242455",
    "updated_at": "2026-01-20 10:15:34.242455",
    "description": null,
    "tasks": "[\"aimo_progress_prize_1\"]"
  },
  {
    "id": 181,
    "dataset_name": "Buy",
    "hf_repo": "lighteval/Buy",
    "author": "lighteval",
    "downloads": 4,
    "tags": "[]",
    "estimated_input_tokens": 38,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-09 14:26:11",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/test-00000-of-00001-ed2e3c23263463b3.parquet\", \"data/train-00000-of-00001-6074f17ba23fe5ef.parquet\", \"data/valid-00000-of-00001-b6e02cf7b281935e.parquet\"]",
    "created_at": "2026-01-20 10:15:36.74627",
    "updated_at": "2026-01-20 10:15:36.74627",
    "description": "More Information needed",
    "tasks": "[\"entity_data_imputation:Buy\"]"
  },
  {
    "id": 182,
    "dataset_name": "IMDB_helm",
    "hf_repo": "lighteval/IMDB_helm",
    "author": "lighteval",
    "downloads": 4,
    "tags": "[]",
    "estimated_input_tokens": 265,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-10 07:26:09",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/test-00000-of-00001-23096865d59dde9c.parquet\", \"data/train-00000-of-00001-1bc06aa30e20029f.parquet\"]",
    "created_at": "2026-01-20 10:15:42.332905",
    "updated_at": "2026-01-20 10:15:42.332905",
    "description": "More Information needed",
    "tasks": "[\"imdb\", \"imdb:contrastset\"]"
  },
  {
    "id": 183,
    "dataset_name": "quac_helm",
    "hf_repo": "lighteval/quac_helm",
    "author": "lighteval",
    "downloads": 4,
    "tags": "[]",
    "estimated_input_tokens": 788,
    "repo_type": "dataset",
    "created_at_hf": "2023-06-14 12:40:42",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"train.jsonl\", \"val.jsonl\"]",
    "created_at": "2026-01-20 10:15:46.584277",
    "updated_at": "2026-01-20 10:15:46.584277",
    "description": null,
    "tasks": "[\"quac\"]"
  },
  {
    "id": 184,
    "dataset_name": "GPT3_unscramble",
    "hf_repo": "lighteval/GPT3_unscramble",
    "author": "lighteval",
    "downloads": 3,
    "tags": "[]",
    "estimated_input_tokens": null,
    "repo_type": "dataset",
    "created_at_hf": "2023-04-19 07:33:20",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/cycle_letters_in_word-00000-of-00001-c498a1851cf993d3.parquet\", \"data/mid_word_1_anagrams-00000-of-00001-d74006de11084179.parquet\", \"data/mid_word_2_anagrams-00000-of-00001-8e0cafb0d7b3be01.parquet\", \"data/random_insertion_in_word-00000-of-00001-51ade0eba051bd17.parquet\", \"data/reversed_words-00000-of-00001-c7a61511f49a89f9.parquet\"]",
    "created_at": "2026-01-20 10:15:49.134967",
    "updated_at": "2026-01-20 10:15:49.134967",
    "description": "More Information needed",
    "tasks": "[\"unscramble:anagrams1\", \"unscramble:anagrams2\", \"unscramble:cycle_letters\", \"unscramble:random_insertion\", \"unscramble:reversed_words\"]"
  },
  {
    "id": 185,
    "dataset_name": "Restaurant",
    "hf_repo": "lighteval/Restaurant",
    "author": "lighteval",
    "downloads": 2,
    "tags": "[]",
    "estimated_input_tokens": 33,
    "repo_type": "dataset",
    "created_at_hf": "2023-05-09 14:30:40",
    "private": false,
    "gated": false,
    "files": "[\".gitattributes\", \"README.md\", \"data/test-00000-of-00001-edd51b6515f54c39.parquet\", \"data/train-00000-of-00001-4a69d581aea69634.parquet\", \"data/valid-00000-of-00001-369a6d3c73de746c.parquet\"]",
    "created_at": "2026-01-20 10:15:53.92837",
    "updated_at": "2026-01-20 10:15:53.92837",
    "description": "More Information needed",
    "tasks": "[\"entity_data_imputation:Restaurant\"]"
  }
]